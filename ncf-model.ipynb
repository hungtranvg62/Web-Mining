{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90ebbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:20.485986Z",
     "iopub.status.busy": "2025-12-28T16:18:20.485375Z",
     "iopub.status.idle": "2025-12-28T16:18:36.239052Z",
     "shell.execute_reply": "2025-12-28T16:18:36.238163Z"
    },
    "papermill": {
     "duration": 15.75907,
     "end_time": "2025-12-28T16:18:36.240649",
     "exception": false,
     "start_time": "2025-12-28T16:18:20.481579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 16:18:22.821814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766938703.009841      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766938703.065690      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766938703.516284      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766938703.516325      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766938703.516328      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766938703.516331      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data! Num Users: 10697, Num Books: 4106\n",
      "Train rows: 82234, Test rows: 20559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# 1. Load the pre-split data\n",
    "# (Assumes train.csv and test.csv are in the input directory)\n",
    "train_df = pd.read_csv('/kaggle/input/book-recommend/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/book-recommend/test.csv')\n",
    "\n",
    "# 2. Recombine briefly to create Lookup Dictionaries\n",
    "# We need these to map \"User 276747\" -> \"ID 45\" without the original LabelEncoder\n",
    "df_full = pd.concat([train_df, test_df])\n",
    "\n",
    "# Map: User_ID -> Encoded_ID\n",
    "user_id_to_encoded = dict(zip(df_full['User_ID'], df_full['user_encoded']))\n",
    "\n",
    "# Map: Book_Title -> Encoded_ID (CRITICAL: This solves your NameError)\n",
    "book_title_to_encoded = dict(zip(df_full['Book_Title'], df_full['book_encoded']))\n",
    "\n",
    "# Map: Encoded_ID -> Book_Title (for printing results)\n",
    "encoded_to_title = dict(zip(df_full['book_encoded'], df_full['Book_Title']))\n",
    "\n",
    "# 3. Prepare Arrays for the Neural Network\n",
    "X_train = train_df[['user_encoded', 'book_encoded']].values\n",
    "y_train = train_df['Book_Rating'].values\n",
    "\n",
    "X_test = test_df[['user_encoded', 'book_encoded']].values\n",
    "y_test = test_df['Book_Rating'].values\n",
    "\n",
    "# 4. Set Model Architecture Constants\n",
    "# The Neural Net needs to know the largest ID to set the Embedding size\n",
    "n_users = df_full['user_encoded'].max() + 1\n",
    "n_books = df_full['book_encoded'].max() + 1\n",
    "\n",
    "print(f\"Loaded Data! Num Users: {n_users}, Num Books: {n_books}\")\n",
    "print(f\"Train rows: {len(X_train)}, Test rows: {len(X_test)}\")\n",
    "\n",
    "# 5. Helpers for the Scorecard (Referee)\n",
    "test_m = csr_matrix(\n",
    "    (y_test, (X_test[:, 0], X_test[:, 1])), \n",
    "    shape=(n_users, n_books)\n",
    ")\n",
    "\n",
    "# Create Popularity Dictionary (Encoded ID -> Count)\n",
    "book_pop_dict = df_full.groupby('book_encoded')['Book_Rating'].count().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6824220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:36.245397Z",
     "iopub.status.busy": "2025-12-28T16:18:36.245124Z",
     "iopub.status.idle": "2025-12-28T16:18:38.344665Z",
     "shell.execute_reply": "2025-12-28T16:18:38.343946Z"
    },
    "papermill": {
     "duration": 2.103365,
     "end_time": "2025-12-28T16:18:38.345966",
     "exception": false,
     "start_time": "2025-12-28T16:18:36.242601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766938716.970071      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ book_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">534,850</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ book_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">205,300</span> │ book_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ book_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ book_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m534,850\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ book_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m205,300\u001b[0m │ book_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ book_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m12,928\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">763,447</span> (2.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m763,447\u001b[0m (2.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">763,447</span> (2.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m763,447\u001b[0m (2.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_ncf_model(num_users, num_items, embedding_size=50):\n",
    "    # Inputs\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    book_input = Input(shape=(1,), name='book_input')\n",
    "\n",
    "    # Embeddings\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, name='user_embedding')(user_input)\n",
    "    book_embedding = Embedding(input_dim=num_items, output_dim=embedding_size, name='book_embedding')(book_input)\n",
    "\n",
    "    # Flatten\n",
    "    user_vec = Flatten()(user_embedding)\n",
    "    book_vec = Flatten()(book_embedding)\n",
    "\n",
    "    # Concatenate & Dense Layers\n",
    "    concat = Concatenate()([user_vec, book_vec])\n",
    "\n",
    "    dense1 = Dense(128, activation='relu')(concat)\n",
    "    dropout1 = Dropout(0.2)(dense1)\n",
    "    dense2 = Dense(64, activation='relu')(dropout1)\n",
    "    dense3 = Dense(32, activation='relu')(dense2)\n",
    "\n",
    "    # Output\n",
    "    output = Dense(1, activation='linear', name='output')(dense3)\n",
    "\n",
    "    model = Model(inputs=[user_input, book_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize\n",
    "ncf_model = build_ncf_model(n_users, n_books)\n",
    "ncf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549511ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:38.352296Z",
     "iopub.status.busy": "2025-12-28T16:18:38.351650Z",
     "iopub.status.idle": "2025-12-28T16:18:58.753189Z",
     "shell.execute_reply": "2025-12-28T16:18:58.752550Z"
    },
    "papermill": {
     "duration": 20.406278,
     "end_time": "2025-12-28T16:18:58.754700",
     "exception": false,
     "start_time": "2025-12-28T16:18:38.348422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766938719.755788      65 service.cc:152] XLA service 0x7eab44009b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1766938719.755825      65 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1766938720.071946      65 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  77/1285\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 51.2039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766938721.295356      65 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 10.7124 - val_loss: 2.4828\n",
      "Epoch 2/5\n",
      "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2589 - val_loss: 2.4464\n",
      "Epoch 3/5\n",
      "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0611 - val_loss: 2.4418\n",
      "Epoch 4/5\n",
      "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8666 - val_loss: 2.4868\n",
      "Epoch 5/5\n",
      "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6412 - val_loss: 2.5653\n"
     ]
    }
   ],
   "source": [
    "history = ncf_model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]], \n",
    "    y_train,                        \n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=([X_test[:, 0], X_test[:, 1]], y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eacb2237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:58.779875Z",
     "iopub.status.busy": "2025-12-28T16:18:58.779272Z",
     "iopub.status.idle": "2025-12-28T16:18:58.784647Z",
     "shell.execute_reply": "2025-12-28T16:18:58.783937Z"
    },
    "papermill": {
     "duration": 0.018899,
     "end_time": "2025-12-28T16:18:58.785879",
     "exception": false,
     "start_time": "2025-12-28T16:18:58.766980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_ncf(user_id, book_title):\n",
    "    # 1. Check if User/Book exists in our lookups\n",
    "    if (user_id not in user_id_to_encoded) or (book_title not in book_title_to_encoded):\n",
    "        # Cold Start: Return global average if unknown\n",
    "        return 7.5\n",
    "\n",
    "    # 2. Get the Integers from the Dictionaries\n",
    "    u_enc = user_id_to_encoded[user_id]\n",
    "    b_enc = book_title_to_encoded[book_title]\n",
    "\n",
    "    # 3. Predict\n",
    "    prediction = ncf_model.predict([np.array([u_enc]), np.array([b_enc])], verbose=0)\n",
    "    \n",
    "    return np.clip(prediction[0][0], 1, 10)\n",
    "\n",
    "# Test it\n",
    "# (Make sure to use a User ID that exists in your train/test CSVs)\n",
    "print(predict_rating_ncf(276747, 'The Lovely Bones: A Novel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b90a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:58.810347Z",
     "iopub.status.busy": "2025-12-28T16:18:58.809716Z",
     "iopub.status.idle": "2025-12-28T16:18:58.816738Z",
     "shell.execute_reply": "2025-12-28T16:18:58.816157Z"
    },
    "papermill": {
     "duration": 0.021124,
     "end_time": "2025-12-28T16:18:58.818249",
     "exception": false,
     "start_time": "2025-12-28T16:18:58.797125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 276747 not found (Cold Start).\n"
     ]
    }
   ],
   "source": [
    "def recommend_ncf(user_id_original, n_recommendations=5):\n",
    "    # 1. Handle Cold Start\n",
    "    if user_id_original not in user_id_to_encoded:\n",
    "        print(f\"User {user_id_original} not found (Cold Start).\")\n",
    "        return []\n",
    "\n",
    "    # 2. Get Encoded User ID (Using Dictionary)\n",
    "    user_int = user_id_to_encoded[user_id_original]\n",
    "\n",
    "    # 3. Find Candidates (Books user has NOT read)\n",
    "    all_books = np.arange(n_books)\n",
    "    \n",
    "    # Get user history from the full dataframe\n",
    "    user_history = df_full[df_full['User_ID'] == user_id_original]['book_encoded'].values\n",
    "    candidates = np.setdiff1d(all_books, user_history)\n",
    "    \n",
    "    # Speed limit: if >1000 candidates, pick random 1000 to score\n",
    "    if len(candidates) > 1000:\n",
    "        candidates = np.random.choice(candidates, size=1000, replace=False)\n",
    "\n",
    "    # 4. Predict\n",
    "    user_input_array = np.full(len(candidates), user_int)\n",
    "    predictions = ncf_model.predict([user_input_array, candidates], batch_size=64, verbose=0).flatten()\n",
    "\n",
    "    # 5. Top N\n",
    "    top_indices = predictions.argsort()[-n_recommendations:][::-1]\n",
    "    top_book_ints = candidates[top_indices]\n",
    "    top_scores = predictions[top_indices]\n",
    "    \n",
    "    # 6. Decode (Using Dictionary)\n",
    "    print(f\"--- NCF Recommendations for User {user_id_original} ---\")\n",
    "    results = []\n",
    "    for book_int, score in zip(top_book_ints, top_scores):\n",
    "        title = encoded_to_title.get(book_int, \"Unknown\")\n",
    "        print(f\"{score:.2f} stars | {title}\")\n",
    "        results.append(title)\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Test\n",
    "recs = recommend_ncf(276747)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec23392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:58.843150Z",
     "iopub.status.busy": "2025-12-28T16:18:58.842816Z",
     "iopub.status.idle": "2025-12-28T16:18:59.160780Z",
     "shell.execute_reply": "2025-12-28T16:18:59.159901Z"
    },
    "papermill": {
     "duration": 0.331947,
     "end_time": "2025-12-28T16:18:59.162354",
     "exception": false,
     "start_time": "2025-12-28T16:18:58.830407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF says these are similar to 'Animal Farm':\n",
      "1: Frankenstein (Changing Our World)\n",
      "2: Fox in Socks (I Can Read It All by Myself Beginner Books)\n",
      "3: The Phantom Tollbooth\n",
      "4: Dead Men Do Tell Tales: The Strange and Fascinating Cases of a Forensic Anthropologist\n",
      "5: The Blue Day Book\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# 1. Extract Embeddings\n",
    "book_weights = ncf_model.get_layer('book_embedding').get_weights()[0]\n",
    "\n",
    "# 2. Fit KNN\n",
    "model_knn_ncf = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_knn_ncf.fit(book_weights)\n",
    "\n",
    "def recommend_similar_ncf(book_title):\n",
    "    # Check if book exists\n",
    "    if book_title not in book_title_to_encoded:\n",
    "        print(f\"Book '{book_title}' not found.\")\n",
    "        return\n",
    "\n",
    "    # Get Integer ID\n",
    "    book_int = book_title_to_encoded[book_title]\n",
    "    \n",
    "    # Find Neighbors\n",
    "    distances, indices = model_knn_ncf.kneighbors(\n",
    "        book_weights[book_int].reshape(1, -1), \n",
    "        n_neighbors=6\n",
    "    )\n",
    "    \n",
    "    print(f\"NCF says these are similar to '{book_title}':\")\n",
    "    for i in range(1, len(indices.flatten())):\n",
    "        idx = indices.flatten()[i]\n",
    "        # Decode using dictionary\n",
    "        similar_title = encoded_to_title.get(idx, \"Unknown\")\n",
    "        print(f\"{i}: {similar_title}\")\n",
    "\n",
    "# Test\n",
    "recommend_similar_ncf('Animal Farm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c15388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:18:59.187255Z",
     "iopub.status.busy": "2025-12-28T16:18:59.186514Z",
     "iopub.status.idle": "2025-12-28T16:19:33.878428Z",
     "shell.execute_reply": "2025-12-28T16:19:33.877663Z"
    },
    "papermill": {
     "duration": 34.717113,
     "end_time": "2025-12-28T16:19:33.891336",
     "exception": false,
     "start_time": "2025-12-28T16:18:59.174223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scoring Model: NCF ---\n",
      "{'Model': 'NCF', 'RMSE (Error)': np.float64(1.4189802808663492), 'NDCG (Ranking)': np.float64(0.9713533809614314), 'Novelty (Popularity)': np.float64(56.528440366972475)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score, mean_squared_error\n",
    "\n",
    "def get_model_scorecard(model_name, test_data_matrix, prediction_function, book_popularity_dict):\n",
    "    \"\"\"\n",
    "    The Universal Referee. \n",
    "    It takes ANY prediction function and returns the 3 critical scores.\n",
    "    \"\"\"\n",
    "    print(f\"--- Scoring Model: {model_name} ---\")\n",
    "    \n",
    "    rmses = []\n",
    "    ndcg_scores = []\n",
    "    novelty_scores = []\n",
    "    \n",
    "    test_users = np.unique(test_data_matrix.nonzero()[0])\n",
    "    # Sample 200 users for speed\n",
    "    sample_users = np.random.choice(test_users, size=min(200, len(test_users)), replace=False)\n",
    "    \n",
    "    for u in sample_users:\n",
    "        true_book_ids = test_data_matrix[u].indices\n",
    "        true_ratings = test_data_matrix[u].data\n",
    "        \n",
    "        if len(true_ratings) < 2: continue \n",
    "        \n",
    "        pred_ratings = []\n",
    "        for book_id in true_book_ids:\n",
    "            # prediction_function must take (user_id, book_id) where these are integers\n",
    "            pred = prediction_function(u, book_id)\n",
    "            pred_ratings.append(pred)\n",
    "            \n",
    "        # RMSE\n",
    "        rmses.append(np.sqrt(mean_squared_error(true_ratings, pred_ratings)))\n",
    "        \n",
    "        # NDCG\n",
    "        try:\n",
    "            ndcg_scores.append(ndcg_score([true_ratings], [pred_ratings]))\n",
    "        except: pass\n",
    "        \n",
    "        # Novelty\n",
    "        top_k_idx = np.argsort(pred_ratings)[::-1][:5]\n",
    "        top_books = true_book_ids[top_k_idx]\n",
    "        pop_score = np.mean([book_popularity_dict.get(b, 0) for b in top_books])\n",
    "        novelty_scores.append(pop_score)\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE (Error)\": np.mean(rmses),\n",
    "        \"NDCG (Ranking)\": np.mean(ndcg_scores),\n",
    "        \"Novelty (Popularity)\": np.mean(novelty_scores)\n",
    "    }\n",
    "\n",
    "# Wrapper for the scorecard\n",
    "def predict_ncf_wrapper(user_int, book_int):\n",
    "    # Predicts single rating for Encoded User u and Encoded Book b\n",
    "    pred = ncf_model.predict([np.array([user_int]), np.array([book_int])], verbose=0)\n",
    "    return np.clip(pred[0][0], 1, 10)\n",
    "\n",
    "# Run Scorecard\n",
    "ncf_scores = get_model_scorecard(\"NCF\", test_m, predict_ncf_wrapper, book_pop_dict)\n",
    "print(ncf_scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9136393,
     "sourceId": 14322837,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 79.027518,
   "end_time": "2025-12-28T16:19:37.095302",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T16:18:18.067784",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
