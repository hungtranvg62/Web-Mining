{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d90144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:23:52.479013Z",
     "iopub.status.busy": "2025-12-28T16:23:52.478595Z",
     "iopub.status.idle": "2025-12-28T16:23:56.425344Z",
     "shell.execute_reply": "2025-12-28T16:23:56.423933Z"
    },
    "papermill": {
     "duration": 3.954206,
     "end_time": "2025-12-28T16:23:56.428288",
     "exception": false,
     "start_time": "2025-12-28T16:23:52.474082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. Users: 10697, Books: 4106\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# 1. Load the pre-split data\n",
    "train_df = pd.read_csv('/kaggle/input/book-recommend/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/book-recommend/test.csv')\n",
    "\n",
    "# 2. Create Lookup Dictionaries (Same as NCF)\n",
    "df_full = pd.concat([train_df, test_df])\n",
    "user_id_to_encoded = dict(zip(df_full['User_ID'], df_full['user_encoded']))\n",
    "book_title_to_encoded = dict(zip(df_full['Book_Title'], df_full['book_encoded']))\n",
    "encoded_to_title = dict(zip(df_full['book_encoded'], df_full['Book_Title']))\n",
    "\n",
    "# 3. Model Constants\n",
    "n_users = df_full['user_encoded'].max() + 1\n",
    "n_books = df_full['book_encoded'].max() + 1\n",
    "\n",
    "# 4. Create Sparse Matrices\n",
    "# KNN requires a matrix (Rows=Users, Cols=Books)\n",
    "train_m = csr_matrix(\n",
    "    (train_df['Book_Rating'].values, (train_df['user_encoded'].values, train_df['book_encoded'].values)), \n",
    "    shape=(n_users, n_books)\n",
    ")\n",
    "\n",
    "test_m = csr_matrix(\n",
    "    (test_df['Book_Rating'].values, (test_df['user_encoded'].values, test_df['book_encoded'].values)), \n",
    "    shape=(n_users, n_books)\n",
    ")\n",
    "\n",
    "# Popularity Dictionary for Scorecard\n",
    "book_pop_dict = df_full.groupby('book_encoded')['Book_Rating'].count().to_dict()\n",
    "\n",
    "print(f\"Data Loaded. Users: {n_users}, Books: {n_books}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9103e95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:23:56.434910Z",
     "iopub.status.busy": "2025-12-28T16:23:56.434539Z",
     "iopub.status.idle": "2025-12-28T16:23:56.442486Z",
     "shell.execute_reply": "2025-12-28T16:23:56.441417Z"
    },
    "papermill": {
     "duration": 0.013764,
     "end_time": "2025-12-28T16:23:56.444595",
     "exception": false,
     "start_time": "2025-12-28T16:23:56.430831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (Cosine) Model Trained!\n"
     ]
    }
   ],
   "source": [
    "# User-Based Collaborative Filtering\n",
    "# We look for users with similar rating patterns (Cosine Similarity)\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# Fit on the Training Matrix\n",
    "model_knn.fit(train_m)\n",
    "\n",
    "print(\"KNN (Cosine) Model Trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee7fbfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:23:56.450837Z",
     "iopub.status.busy": "2025-12-28T16:23:56.450444Z",
     "iopub.status.idle": "2025-12-28T16:23:56.459569Z",
     "shell.execute_reply": "2025-12-28T16:23:56.458470Z"
    },
    "papermill": {
     "duration": 0.015297,
     "end_time": "2025-12-28T16:23:56.462117",
     "exception": false,
     "start_time": "2025-12-28T16:23:56.446820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_cosine(user_id, book_title):\n",
    "    # 1. Check if User/Book exists\n",
    "    if (user_id not in user_id_to_encoded) or (book_title not in book_title_to_encoded):\n",
    "        return 7.5 # Default\n",
    "\n",
    "    u_enc = user_id_to_encoded[user_id]\n",
    "    b_enc = book_title_to_encoded[book_title]\n",
    "    \n",
    "    # 2. Find Nearest Neighbors for this User\n",
    "    # Returns distances and indices of the K nearest users\n",
    "    distances, indices = model_knn.kneighbors(train_m[u_enc], n_neighbors=20)\n",
    "    \n",
    "    # Flatten\n",
    "    neighbor_indices = indices.flatten()\n",
    "    neighbor_distances = distances.flatten()\n",
    "    \n",
    "    # 3. Calculate Weighted Average\n",
    "    # We only care about neighbors who actually rated the target book 'b_enc'\n",
    "    # Get ratings of neighbors for this specific book\n",
    "    neighbor_ratings = train_m[neighbor_indices, b_enc].toarray().flatten()\n",
    "    \n",
    "    # Filter out zeros (neighbors who didn't read this book)\n",
    "    mask = neighbor_ratings > 0\n",
    "    relevant_ratings = neighbor_ratings[mask]\n",
    "    relevant_distances = neighbor_distances[mask]\n",
    "    \n",
    "    if len(relevant_ratings) == 0:\n",
    "        return 7.5 # None of the similar users read this book\n",
    "        \n",
    "    # Weight by similarity (1 - distance) because Cosine Distance = 1 - Cosine Similarity\n",
    "    similarities = 1 - relevant_distances\n",
    "    \n",
    "    if np.sum(similarities) == 0:\n",
    "        return np.mean(relevant_ratings)\n",
    "        \n",
    "    prediction = np.dot(relevant_ratings, similarities) / np.sum(similarities)\n",
    "    \n",
    "    return np.clip(prediction, 1, 10)\n",
    "\n",
    "# Test\n",
    "print(predict_rating_cosine(276747, 'The Lovely Bones: A Novel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982d62d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:23:56.472286Z",
     "iopub.status.busy": "2025-12-28T16:23:56.471896Z",
     "iopub.status.idle": "2025-12-28T16:23:56.480934Z",
     "shell.execute_reply": "2025-12-28T16:23:56.479597Z"
    },
    "papermill": {
     "duration": 0.017606,
     "end_time": "2025-12-28T16:23:56.483977",
     "exception": false,
     "start_time": "2025-12-28T16:23:56.466371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recommend_cosine(user_id_original, n_recommendations=5):\n",
    "    if user_id_original not in user_id_to_encoded:\n",
    "        return []\n",
    "\n",
    "    u_enc = user_id_to_encoded[user_id_original]\n",
    "    \n",
    "    # 1. Find Neighbors\n",
    "    distances, indices = model_knn.kneighbors(train_m[u_enc], n_neighbors=10)\n",
    "    neighbor_indices = indices.flatten()\n",
    "    \n",
    "    # 2. Get Neighbors' Top Books\n",
    "    # We sum up the ratings from all neighbors for all books\n",
    "    neighbor_ratings_sum = np.array(train_m[neighbor_indices].sum(axis=0)).flatten()\n",
    "    \n",
    "    # 3. Filter out books user has already read\n",
    "    user_history = train_m[u_enc].indices\n",
    "    neighbor_ratings_sum[user_history] = 0 # Zero out read books\n",
    "    \n",
    "    # 4. Get Top N\n",
    "    top_indices = neighbor_ratings_sum.argsort()[-n_recommendations:][::-1]\n",
    "    \n",
    "    # 5. Decode\n",
    "    print(f\"--- Cosine Recommendations for User {user_id_original} ---\")\n",
    "    results = []\n",
    "    for book_int in top_indices:\n",
    "        # Only recommend if score > 0\n",
    "        if neighbor_ratings_sum[book_int] == 0: continue\n",
    "            \n",
    "        title = encoded_to_title.get(book_int, \"Unknown\")\n",
    "        print(f\"Score {neighbor_ratings_sum[book_int]:.1f} | {title}\")\n",
    "        results.append(title)\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Test\n",
    "recs = recommend_cosine(276747)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc26b6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:23:56.492225Z",
     "iopub.status.busy": "2025-12-28T16:23:56.491855Z",
     "iopub.status.idle": "2025-12-28T16:23:56.520387Z",
     "shell.execute_reply": "2025-12-28T16:23:56.518873Z"
    },
    "papermill": {
     "duration": 0.036173,
     "end_time": "2025-12-28T16:23:56.522960",
     "exception": false,
     "start_time": "2025-12-28T16:23:56.486787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine says these are similar to 'Animal Farm':\n",
      "1: 1984\n",
      "2: The Green Mile: The Mouse on the Mile (Green Mile Series)\n",
      "3: Tis: A Memoir\n",
      "4: Losing Julia\n",
      "5: The Green Mile: Coffey on the Mile (Green Mile Series)\n"
     ]
    }
   ],
   "source": [
    "# Create Item-Item Model (Fit on Transpose)\n",
    "# This finds books with similar rating patterns\n",
    "model_item_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)\n",
    "model_item_knn.fit(train_m.T) # Note the .T (Transpose)\n",
    "\n",
    "def recommend_similar_cosine(book_title):\n",
    "    if book_title not in book_title_to_encoded:\n",
    "        print(\"Book not found.\")\n",
    "        return\n",
    "\n",
    "    b_enc = book_title_to_encoded[book_title]\n",
    "    \n",
    "    # Find Nearest Books\n",
    "    distances, indices = model_item_knn.kneighbors(train_m.T[b_enc], n_neighbors=6)\n",
    "    \n",
    "    print(f\"Cosine says these are similar to '{book_title}':\")\n",
    "    for i in range(1, len(indices.flatten())):\n",
    "        idx = indices.flatten()[i]\n",
    "        title = encoded_to_title.get(idx, \"Unknown\")\n",
    "        print(f\"{i}: {title}\")\n",
    "\n",
    "# Test\n",
    "recommend_similar_cosine('Animal Farm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa551a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:23:56.530295Z",
     "iopub.status.busy": "2025-12-28T16:23:56.529949Z",
     "iopub.status.idle": "2025-12-28T16:24:01.967152Z",
     "shell.execute_reply": "2025-12-28T16:24:01.965815Z"
    },
    "papermill": {
     "duration": 5.443972,
     "end_time": "2025-12-28T16:24:01.969277",
     "exception": false,
     "start_time": "2025-12-28T16:23:56.525305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scoring Model: Cosine (KNN) ---\n",
      "{'Model': 'Cosine (KNN)', 'RMSE': np.float64(1.967552140998551), 'NDCG': np.float64(0.9541488724623698), 'Novelty': np.float64(49.18641975308642)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. FAST WRAPPER (Required for efficient scoring) ---\n",
    "def predict_cosine_wrapper(u_enc, b_enc):\n",
    "    \"\"\"\n",
    "    Fast prediction using Integers directly.\n",
    "    Bypasses the dictionary lookups to speed up the loop.\n",
    "    \"\"\"\n",
    "    # 1. Find neighbors for the User (u_enc)\n",
    "    distances, indices = model_knn.kneighbors(train_m[u_enc], n_neighbors=20)\n",
    "    neighbor_indices = indices.flatten()\n",
    "    neighbor_distances = distances.flatten()\n",
    "    \n",
    "    # 2. Get ratings for the Book (b_enc) from these neighbors\n",
    "    # We index the sparse matrix directly\n",
    "    neighbor_ratings = train_m[neighbor_indices, b_enc].toarray().flatten()\n",
    "    \n",
    "    # 3. Filter: Keep only neighbors who actually rated this book\n",
    "    mask = neighbor_ratings > 0\n",
    "    relevant_ratings = neighbor_ratings[mask]\n",
    "    relevant_distances = neighbor_distances[mask]\n",
    "    \n",
    "    # 4. Handle Edge Cases\n",
    "    if len(relevant_ratings) == 0:\n",
    "        return 7.5 # Default if no neighbors read it\n",
    "        \n",
    "    # 5. Weighted Average Calculation\n",
    "    # Similarity = 1 - Distance (approx)\n",
    "    similarities = 1 - relevant_distances\n",
    "    \n",
    "    if np.sum(similarities) == 0:\n",
    "        return np.mean(relevant_ratings)\n",
    "        \n",
    "    pred = np.dot(relevant_ratings, similarities) / np.sum(similarities)\n",
    "    return np.clip(pred, 1, 10)\n",
    "\n",
    "# --- 2. THE SCORECARD FUNCTION ---\n",
    "def get_model_scorecard(model_name, test_data_matrix, prediction_function, book_popularity_dict):\n",
    "    print(f\"--- Scoring Model: {model_name} ---\")\n",
    "    rmses = []\n",
    "    ndcg_scores = []\n",
    "    novelty_scores = []\n",
    "    \n",
    "    # Identify users in the test set\n",
    "    test_users = np.unique(test_data_matrix.nonzero()[0])\n",
    "    \n",
    "    # Sample 100 users\n",
    "    # (KNN is much slower than NCF, so we sample 100 instead of 200 to save time)\n",
    "    n_sample = min(100, len(test_users))\n",
    "    sample_users = np.random.choice(test_users, size=n_sample, replace=False)\n",
    "    \n",
    "    for u in sample_users:\n",
    "        # Get Truth (What user really rated)\n",
    "        true_book_ids = test_data_matrix[u].indices\n",
    "        true_ratings = test_data_matrix[u].data\n",
    "        \n",
    "        if len(true_ratings) < 2: continue \n",
    "        \n",
    "        # Get Predictions (Ask our model)\n",
    "        pred_ratings = []\n",
    "        for book_id in true_book_ids:\n",
    "            pred = prediction_function(u, book_id)\n",
    "            pred_ratings.append(pred)\n",
    "            \n",
    "        # --- Metric A: RMSE (Accuracy) ---\n",
    "        rmses.append(np.sqrt(mean_squared_error(true_ratings, pred_ratings)))\n",
    "        \n",
    "        # --- Metric B: NDCG (Ranking) ---\n",
    "        try:\n",
    "            ndcg_scores.append(ndcg_score([true_ratings], [pred_ratings]))\n",
    "        except: pass\n",
    "        \n",
    "        # --- Metric C: Novelty (Discovery) ---\n",
    "        top_k_idx = np.argsort(pred_ratings)[::-1][:5]\n",
    "        top_books = true_book_ids[top_k_idx]\n",
    "        pop_score = np.mean([book_popularity_dict.get(b, 0) for b in top_books])\n",
    "        novelty_scores.append(pop_score)\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE\": np.mean(rmses),\n",
    "        \"NDCG\": np.mean(ndcg_scores),\n",
    "        \"Novelty\": np.mean(novelty_scores)\n",
    "    }\n",
    "\n",
    "# --- 3. RUN EVALUATION ---\n",
    "# 'test_m' and 'book_pop_dict' were created in Cell 1\n",
    "cosine_scores = get_model_scorecard(\"Cosine (KNN)\", test_m, predict_cosine_wrapper, book_pop_dict)\n",
    "print(cosine_scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9136393,
     "sourceId": 14322837,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.867731,
   "end_time": "2025-12-28T16:24:02.593828",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T16:23:48.726097",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
